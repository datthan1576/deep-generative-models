{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mg5oRBoOWloW"
   },
   "source": [
    "## Task 1: Theory (3pt)\n",
    "\n",
    "1. Let's recall the variational lower bound for the discrete data dequantization problem from Lecture 8:\n",
    "$$\n",
    "    \\log P(\\mathbf{x} | \\boldsymbol{\\theta}) \\geq  \\int q(\\mathbf{u} | \\mathbf{x}) \\log \\frac{p(\\mathbf{x} + \\mathbf{u} | \\boldsymbol{\\theta})}{q(\\mathbf{u} | \\mathbf{x})} d \\mathbf{u} = \\mathcal{L}(q, \\boldsymbol{\\theta}).\n",
    "$$\n",
    "We have discussed with you that the variational lower bound can be improved with the help of Importance Sampling. Write out the lower bound for dequantization using $\\mathcal{L}_k$ by analogy with the IWAE model (you need to use not just one $\\mathbf{u}$, but a set of $\\{\\mathbf{u}_k\\}_{k=1}^K$).\n",
    "    \n",
    "2. The Vanilla GAN often suffers from problems with a saturating gradient. [Least Squares GAN](https://arxiv.org/abs/1611.04076) tries to solve this problem by replacing the error function with the following:\n",
    "$$\n",
    "   \t\\min_D V(D) = \\min_D \\frac{1}{2}\\left[ \\mathbb{E}_{\\pi(\\mathbf{x})} (D(\\mathbf{x}) - b)^2 + \\mathbb{E}_{p(\\mathbf{z})} (D(G(\\mathbf{z})) - a)^2 \\right]\n",
    "$$\n",
    "$$\n",
    "   \t\\min_G V(G) = \\min_G \\frac{1}{2}\\left[ \\mathbb{E}_{\\pi(\\mathbf{x})} (D(\\mathbf{x}) - c)^2 + \\mathbb{E}_{p(\\mathbf{z})} (D(G(\\mathbf{z})) - c)^2 \\right],\n",
    "$$\n",
    "where $a,b,c \\in \\mathbb{R}$ some fixed constants.\n",
    "    * Find the formula for the optimal discriminator $D^*$.\n",
    "    *  \\textbf{(1 pt)} Write out the expression of the error function of the generator $V(G)$ in the case of an optimal discriminator $D^*$.\n",
    "    * \\textbf{(1.5 pt)} Prove that for $b - c = 1$, $b - a = 2$, the error function of the generator $V(G)$ in the case of the optimal discriminator $D^*$ takes the form:\n",
    "$$\n",
    "   \tV(G) = \\frac{1}{2} \\chi^2_{\\text{Pearson}} (\\pi(\\mathbf{x}) + p(\\mathbf{x} | \\boldsymbol{\\theta}) || 2 p(\\mathbf{x} | \\boldsymbol{\\theta})), \n",
    "$$\n",
    "where $\\chi^2_{\\text{Pearson}} (p || q)$ is a squared Pearson divergence:\n",
    "$$\n",
    "   \t\\chi^2_{\\text{Pearson}} (p || q) = \\int \\frac{(p(\\mathbf{x}) - q(\\mathbf{x}))^2}{p(\\mathbf{x})} d \\mathbf{x}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kwS2oTkaVLct"
   },
   "source": [
    "```your solution```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qCNBV60b8CHX",
    "outputId": "106f99fe-9189-4328-f386-93fe545089d4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "print('cuda is available:', USE_CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mQb5MtUKd_ii",
    "outputId": "906c5b98-a4db-4a44-fc27-de52e20254e2"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ftMgDK_cPFmD"
   },
   "outputs": [],
   "source": [
    "def plot_losses(losses, title):\n",
    "    n_itr = len(losses)\n",
    "    xs = np.arange(n_itr)\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.plot(xs, losses)\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.xlabel('Iterations', fontsize=14)\n",
    "    plt.ylabel('Loss', fontsize=14)\n",
    "\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p_mQWXNLGZxp"
   },
   "source": [
    "# Task 2: Vanila GAN for 1d task (3pt)\n",
    "\n",
    "In this task you will train simple GAN model for 1d distribution (mixture of 2 gaussians)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2aSnhquU8zUk"
   },
   "outputs": [],
   "source": [
    "def generate_1d_data(count):\n",
    "    gaussian1 = np.random.normal(loc=-1, scale=0.25, size=(count // 2,))\n",
    "    gaussian2 = np.random.normal(loc=0.5, scale=0.5, size=(count // 2,))\n",
    "    data = (np.concatenate([gaussian1, gaussian2]) + 1).reshape([-1, 1]).astype('float32')\n",
    "    return (data - data.min()) / (data.max() - data.min())\n",
    "\n",
    "\n",
    "def visualize_1d_data(data):\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.hist(data, bins=50)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def make_inference(generator, discriminator, n_samples=5000):\n",
    "    generator.eval()\n",
    "    discriminator.eval()\n",
    "    xs = np.linspace(0, 1, 1000)\n",
    "    samples = generator.sample(n_samples).cpu().detach().numpy()\n",
    "    discr_output = discriminator(torch.FloatTensor(xs).cuda().unsqueeze(1)).cpu().detach().numpy()\n",
    "    return samples, xs, discr_output\n",
    "\n",
    "\n",
    "def plot_results(data, samples, xs, ys, title):\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.hist(samples, bins=50, density=True, alpha=0.7, label='fake')\n",
    "    plt.hist(data, bins=50, density=True, alpha=0.7, label='real')\n",
    "\n",
    "    plt.plot(xs, ys, label='discrim')\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "id": "FZWKQr5R-3wF",
    "outputId": "1de7db2f-acf0-47d1-98f0-3aa8e9663872"
   },
   "outputs": [],
   "source": [
    "COUNT = 20000\n",
    "\n",
    "train_data = generate_1d_data(COUNT)\n",
    "visualize_1d_data(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G6C33e_niKdf"
   },
   "source": [
    "The next functions help you to train your model. Read them carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Np-gRwq9-7HT"
   },
   "outputs": [],
   "source": [
    "def make_step(loss_fn, x, generator, discriminator, optimizer):\n",
    "    loss = loss_fn(generator, discriminator, x)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "\n",
    "def train_epoch(\n",
    "    generator, \n",
    "    discriminator, \n",
    "    gen_loss_fn, \n",
    "    discr_loss_fn, \n",
    "    train_loader, \n",
    "    gen_optimizer, \n",
    "    discr_optimizer, \n",
    "    discr_steps,\n",
    "    use_cuda\n",
    "):\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "\n",
    "    gen_losses, discr_losses = [], []\n",
    "    for idx, x in enumerate(train_loader):\n",
    "        if use_cuda:\n",
    "            x = x.cuda()\n",
    "        discr_loss = make_step(discr_loss_fn, x, generator, discriminator, discr_optimizer)\n",
    "        discr_losses.append(discr_loss.item())\n",
    "\n",
    "        if idx % discr_steps == 0:\n",
    "            gen_loss = make_step(gen_loss_fn, x, generator, discriminator, gen_optimizer)\n",
    "            gen_losses.append(gen_loss.item())\n",
    "    return {\n",
    "        'generator_losses': gen_losses,\n",
    "        'discriminator_losses': discr_losses\n",
    "    }\n",
    "\n",
    "\n",
    "def train_gan(\n",
    "    generator, \n",
    "    discriminator, \n",
    "    gen_loss_fn, \n",
    "    discr_loss_fn, \n",
    "    train_loader, \n",
    "    epochs,\n",
    "    lr,\n",
    "    discr_steps=1,\n",
    "    use_tqdm=False, \n",
    "    use_cuda=False\n",
    "):\n",
    "    gen_optimizer = optim.Adam(generator.parameters(), lr=lr, betas=(0, 0.9))\n",
    "    discr_optimizer = optim.Adam(discriminator.parameters(), lr=lr, betas=(0, 0.9))\n",
    "\n",
    "    if use_cuda:\n",
    "        generator = generator.cuda()\n",
    "        discriminator = discriminator.cuda()\n",
    "\n",
    "    train_losses = {}\n",
    "    forrange = tqdm(range(epochs)) if use_tqdm else range(epochs)\n",
    "    for epoch in forrange:\n",
    "        train_loss = train_epoch(\n",
    "            generator, \n",
    "            discriminator, \n",
    "            gen_loss_fn, \n",
    "            discr_loss_fn,\n",
    "            train_loader, \n",
    "            gen_optimizer, \n",
    "            discr_optimizer, \n",
    "            discr_steps=discr_steps,\n",
    "            use_cuda=use_cuda\n",
    "        )\n",
    "        \n",
    "        for k in train_loss.keys():\n",
    "            if k not in train_losses:\n",
    "                train_losses[k] = []\n",
    "            train_losses[k].extend(train_loss[k])\n",
    "\n",
    "    return train_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDRuBWI5HJvl"
   },
   "source": [
    "Generator and Discriminator models are simple MLP models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XBY9rHAps4hn"
   },
   "outputs": [],
   "source": [
    "class FullyConnectedMLP(nn.Module):\n",
    "    # do not change this class\n",
    "    def __init__(self, input_dim, hiddens, output_dim):\n",
    "        assert isinstance(hiddens, list)\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.hiddens = hiddens\n",
    "\n",
    "        # ====\n",
    "        # your code\n",
    "        # stack Linear layear and ReLU (the last layer shoud be Linear)\n",
    "        \n",
    "        \n",
    "        # ====\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ====\n",
    "        # your code\n",
    "        \n",
    "        \n",
    "        # ===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "usTdzZirKoyE"
   },
   "outputs": [],
   "source": [
    "class MLPGenerator(nn.Module):\n",
    "    def __init__(self, latent_dim, hiddens, data_dim, use_sigmoid=False):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.use_sigmoid = use_sigmoid\n",
    "        # ====\n",
    "        # your code\n",
    "        # define mlp\n",
    "        \n",
    "        # ====\n",
    "    \n",
    "    def forward(self, z):\n",
    "        # ====\n",
    "        # your code\n",
    "        # 1) apply mlp \n",
    "        # 2) use_sigmoid flag means that data is from 0 to 1, apply sigmoid function to the output if flag is True\n",
    "\n",
    "        # ====\n",
    "        \n",
    "    def sample(self, n):\n",
    "        # ====\n",
    "        # your code\n",
    "        # sample from standard normal distribution and apply the model\n",
    "\n",
    "        # ====\n",
    "\n",
    "\n",
    "class MLPDiscriminator(nn.Module):\n",
    "    def __init__(self, data_dim, hiddens, use_sigmoid=False):\n",
    "        super().__init__()\n",
    "        self.use_sigmoid = use_sigmoid\n",
    "        # ====\n",
    "        # your code\n",
    "        # define mlp\n",
    "\n",
    "        # ====\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # ====\n",
    "        # your code\n",
    "        # 1) apply mlp\n",
    "        # 2) use_sigmoid flag means that discriminator outputs the value from 0 to 1\n",
    "        #    apply sigmoid function to the output if flag is True\n",
    "\n",
    "        # ===="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M1qerw4Nbhj2"
   },
   "source": [
    "The objective function is \n",
    "$$\\min_{G} \\max_{D} \\mathbb{E}_{\\mathbf{x} \\sim \\pi(\\mathbf{x})} [\\log D(\\mathbf{x})] + \\mathbb{E}_{\\mathbf{z} \\sim p(\\mathbf{z})}[\\log (1-D(G(\\mathbf{z})))]$$\n",
    "\n",
    "Now you have to implement the objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UvUu68X7bdhU"
   },
   "outputs": [],
   "source": [
    "def gen_loss_fn(generator, discriminator, x):\n",
    "    # ====\n",
    "    # your code\n",
    "    # sample data from generator (number of samples = x.shape[0])\n",
    "\n",
    "    # ====\n",
    "\n",
    "\n",
    "def discr_loss_fn(generator, discriminator, x):\n",
    "    # ====\n",
    "    # your code\n",
    "    # sample data from generator (number of samples = x.shape[0])\n",
    "\n",
    "    # ===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "5e87b91ffa4547a3babaaa36950f900f",
      "36c80d2acaa84e31ac6adfa58abe3c95",
      "6080bfc01258436ab0895d9a1f6e54c2",
      "12081ffdd81b4ed8b3dafcfeba20f038",
      "4eb609f28a6a4d2682cd395078b66811",
      "df95f674f8984c75ab91fdc406a26d35",
      "9936d1fdacf14b8c88a8b78f766c76e8",
      "39d2d0e8dd244b878f3ffac072857735",
      "8e21e39a6e174ff89a8c1d610ac8b33a",
      "528331135467479c8b751660bdd63da8",
      "7a03b575469541f098b13ce9cb25616f"
     ]
    },
    "id": "qcQEyAkCMERX",
    "outputId": "56a21eec-ed87-481b-8783-29a53f457fd5"
   },
   "outputs": [],
   "source": [
    "# ====\n",
    "# your code\n",
    "# choose these parameters\n",
    "BATCH_SIZE = \n",
    "GEN_HIDDENS = \n",
    "DISCR_HIDDENS = \n",
    "EPOCHS = \n",
    "LR = \n",
    "DISCR_STEPS = \n",
    "# ====\n",
    "\n",
    "train_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "generator = MLPGenerator(latent_dim=1, hiddens=GEN_HIDDENS, data_dim=1, use_sigmoid=True)\n",
    "discriminator = MLPDiscriminator(data_dim=1, hiddens=DISCR_HIDDENS, use_sigmoid=True)\n",
    "\n",
    "# train\n",
    "train_losses = train_gan(\n",
    "    generator, \n",
    "    discriminator, \n",
    "    gen_loss_fn, \n",
    "    discr_loss_fn, \n",
    "    train_loader, \n",
    "    epochs=EPOCHS,\n",
    "    lr=LR,\n",
    "    discr_steps=DISCR_STEPS,\n",
    "    use_tqdm=True,\n",
    "    use_cuda=USE_CUDA\n",
    ")\n",
    "\n",
    "plot_losses(train_losses['discriminator_losses'], 'Discriminator loss')\n",
    "plot_losses(train_losses['generator_losses'], 'Generator loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yy8IpWG9L5f-"
   },
   "outputs": [],
   "source": [
    "samples, xs, discr_output = make_inference(generator, discriminator)\n",
    "plot_results(train_data, samples, xs, discr_output, 'Results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S4JTKu_GKd5A"
   },
   "source": [
    "Now we'll use the non-saturating formulation of the GAN objective. In this case we have two separate losses:\n",
    "$$\n",
    "    L^{(D)} = \\mathbb{E}_{\\mathbf{x} \\sim \\pi(\\mathbf{x})} [\\log D(\\mathbf{x})] + \\mathbb{E}_{\\mathbf{z} \\sim p(\\mathbf{z})}[\\log (1-D(G(\\mathbf{z})))]\n",
    "$$\n",
    "$$\n",
    "    L^{(G)} = - \\mathbb{E}_{\\mathbf{z} \\sim p(\\mathbf{z})} \\log(D(G(\\mathbf{z}))\n",
    "$$\n",
    "\n",
    "The discriminator loss is the same, we have to change generator loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2mWVP91lb_es"
   },
   "outputs": [],
   "source": [
    "def gen_nonsaturating_loss_fn(generator, discriminator, x):\n",
    "    # ====\n",
    "    # your code\n",
    "    # sample data from generator (number of samples = x.shape[0])\n",
    "\n",
    "    # ===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A76u5yydQODY"
   },
   "outputs": [],
   "source": [
    "# ====\n",
    "# your code\n",
    "# choose these parameters\n",
    "BATCH_SIZE = \n",
    "GEN_HIDDENS = \n",
    "DISCR_HIDDENS =\n",
    "EPOCHS = \n",
    "LR = \n",
    "DISCR_STEPS = \n",
    "# ====\n",
    "\n",
    "train_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# model\n",
    "generator = MLPGenerator(latent_dim=1, hiddens=GEN_HIDDENS, data_dim=1, use_sigmoid=True)\n",
    "discriminator = MLPDiscriminator(data_dim=1, hiddens=DISCR_HIDDENS, use_sigmoid=True)\n",
    "\n",
    "# train\n",
    "train_losses = train_gan(\n",
    "    generator, \n",
    "    discriminator, \n",
    "    gen_nonsaturating_loss_fn, \n",
    "    discr_loss_fn, \n",
    "    train_loader, \n",
    "    epochs=EPOCHS,\n",
    "    lr=LR,\n",
    "    discr_steps=DISCR_STEPS,\n",
    "    use_tqdm=True,\n",
    "    use_cuda=USE_CUDA\n",
    ")\n",
    "\n",
    "plot_losses(train_losses['discriminator_losses'], 'Discriminator loss')\n",
    "plot_losses(train_losses['generator_losses'], 'Generator loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aV_y2bGgQ40M"
   },
   "outputs": [],
   "source": [
    "samples, xs, discr_output = make_inference(generator, discriminator)\n",
    "plot_results(train_data, samples, xs, discr_output, 'Results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eF2vatv9ikAi"
   },
   "source": [
    "# Task 3: WGAN vs WGAN-GP on 2d data (3pt)\n",
    "\n",
    "Here your task is to reproduce the experiment with a toy dataset from [WGAN-GP](https://arxiv.org/pdf/1704.00028.pdf) paper.\n",
    "\n",
    "Let generate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VTkzYqkufT-W"
   },
   "outputs": [],
   "source": [
    "def generate_2d_data(size):\n",
    "    scale = 2\n",
    "    var = 0.02\n",
    "    centers = [\n",
    "        (1, 0),\n",
    "        (-1, 0),\n",
    "        (0, 1),\n",
    "        (0, -1),\n",
    "        (1. / np.sqrt(2), 1. / np.sqrt(2)),\n",
    "        (1. / np.sqrt(2), -1. / np.sqrt(2)),\n",
    "        (-1. / np.sqrt(2), 1. / np.sqrt(2)),\n",
    "        (-1. / np.sqrt(2), -1. / np.sqrt(2))\n",
    "    ]\n",
    "    \n",
    "    centers = [(scale * x, scale * y) for x, y in centers]\n",
    "    dataset = []\n",
    "    \n",
    "    for i in range(size):    \n",
    "        point = np.random.randn(2) * var\n",
    "        center = centers[np.random.choice(np.arange(len(centers)))]\n",
    "        point[0] += center[0]\n",
    "        point[1] += center[1]\n",
    "        dataset.append(point)\n",
    "        \n",
    "    dataset = np.array(dataset, dtype='float32')\n",
    "    dataset /= 1.414  # stdev\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "def visualize_2d_data(train_data, train_labels=None):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.title('train data', fontsize=14)\n",
    "    plt.scatter(train_data[:, 0], train_data[:, 1], s=1, c=train_labels)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pB58-3K7iuXs"
   },
   "outputs": [],
   "source": [
    "COUNT = 20000\n",
    "\n",
    "train_data = generate_2d_data(COUNT)\n",
    "visualize_2d_data(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7D48JfdjRCG"
   },
   "source": [
    "The data has lots of separate modes. Our goal is to compare WGAN with WGAN-GP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lN8eEktgipYY"
   },
   "outputs": [],
   "source": [
    "def make_inference(generator, critic, n_samples=5000):\n",
    "    generator.eval()\n",
    "    critic.eval()\n",
    "    xs = np.linspace(-3.0, 3.0, 1000 + 1)\n",
    "    xg, yg = np.meshgrid(xs, xs)\n",
    "    grid = np.concatenate((xg.reshape(-1, 1), yg.reshape(-1, 1)), axis=-1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        samples = generator.sample(n_samples).cpu().detach().numpy()\n",
    "        critic_output = critic(torch.FloatTensor(grid).cuda()).cpu().detach().numpy()\n",
    "    \n",
    "    critic_output = np.prod(critic_output, axis=-1).reshape((1000 + 1, 1000 + 1))\n",
    "    return samples, grid, critic_output\n",
    "\n",
    "\n",
    "def visualize_critic_output(samples, grid, critic_output, npts=100 + 1):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.gca().set_aspect(\"equal\")\n",
    "    \n",
    "    npts = critic_output.shape[0]\n",
    "    cnt = plt.contourf(\n",
    "        grid[:, 0].reshape((npts, npts)), grid[:, 1].reshape((npts, npts)), critic_output,\n",
    "        levels=25, cmap=\"cividis\"\n",
    "    )\n",
    "    plt.scatter(samples[:, 0], samples[:, 1], marker=\".\", color=\"red\", s=0.5)\n",
    "    plt.colorbar(cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8klUHHmAjHsI"
   },
   "source": [
    "## WGAN\n",
    "\n",
    "[WGAN](https://arxiv.org/abs/1701.07875) model uses weight clipping to enforce Lipschitzness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "echIwLvki0LF"
   },
   "outputs": [],
   "source": [
    "# WGAN train loop\n",
    "\n",
    "def train_wgan(\n",
    "    generator, \n",
    "    critic, \n",
    "    train_loader,\n",
    "    critic_steps, \n",
    "    batch_size,\n",
    "    n_epochs,\n",
    "    lr, \n",
    "    clip_c,\n",
    "    use_cuda\n",
    "):\n",
    "    train_losses = []\n",
    "\n",
    "    if use_cuda:\n",
    "        generator = generator.cuda()\n",
    "        critic = critic.cuda()\n",
    "\n",
    "    gen_optimizer = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0, 0.9))\n",
    "    critic_optimizer = torch.optim.Adam(critic.parameters(), lr=lr, betas=(0, 0.9))\n",
    "\n",
    "    generator.train()\n",
    "    critic.train()\n",
    "\n",
    "    curr_iter = 0\n",
    "    d_loss, g_loss = torch.zeros(1), torch.zeros(1)\n",
    "    \n",
    "    batch_loss_history = {'discriminator_losses': [], 'generator_losses': []}\n",
    "    for epoch_i in range(n_epochs):\n",
    "\n",
    "        with tqdm(train_loader, desc=f\"epoch {epoch_i}\", leave=False) as pbar:\n",
    "            for (batch_i, x) in enumerate(pbar):\n",
    "                curr_iter += 1\n",
    "                if use_cuda:\n",
    "                    x = x.cuda()\n",
    "\n",
    "                # do a critic update\n",
    "                with torch.no_grad():\n",
    "                    fake_data = generator.sample(x.shape[0])\n",
    "                \n",
    "                critic_optimizer.zero_grad()\n",
    "                \n",
    "                # ====\n",
    "                # your code\n",
    "                # compute discriminator loss as D(x_fake) - D(x_real)\n",
    "\n",
    "                # ====\n",
    "                d_loss.backward()\n",
    "                critic_optimizer.step()\n",
    "                critic.clip_weights(clip_c)\n",
    "                pbar.set_postfix({\"D loss\": d_loss.item(), \"G loss\": g_loss.item()})\n",
    "\n",
    "                # generator update\n",
    "                if curr_iter % critic_steps == 0:\n",
    "                    gen_optimizer.zero_grad()\n",
    "                    fake_data = generator.sample(batch_size)\n",
    "                    \n",
    "                    # ====\n",
    "                    # your code\n",
    "                    # compute generator loss as -D(x_fake)\n",
    "\n",
    "                    # ====\n",
    "                    g_loss.backward()\n",
    "                    gen_optimizer.step()\n",
    "                    pbar.set_postfix({\"D loss\": d_loss.item(), \"G loss\": g_loss.item()})\n",
    "\n",
    "                    batch_loss_history['generator_losses'].append(g_loss.data.cpu().numpy())\n",
    "                    batch_loss_history['discriminator_losses'].append(d_loss.data.cpu().numpy())\n",
    "\n",
    "    return batch_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NGesm5J9jKyr"
   },
   "outputs": [],
   "source": [
    "# ====\n",
    "# your code\n",
    "# choose these parameters\n",
    "BATCH_SIZE = \n",
    "GEN_HIDDENS = \n",
    "DISCR_HIDDENS = \n",
    "CRITIC_STEPS = \n",
    "LR = \n",
    "CLIP_C = \n",
    "# ====\n",
    "\n",
    "N_EPOCHS = 200\n",
    "\n",
    "train_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "generator = MLPGenerator(latent_dim=16, hiddens=GEN_HIDDENS, data_dim=2, use_sigmoid=False)\n",
    "critic = MLPCritic(data_dim=2, hiddens=DISCR_HIDDENS, use_sigmoid=False)\n",
    "\n",
    "train_losses = train_wgan(\n",
    "    generator, \n",
    "    critic, \n",
    "    train_loader,\n",
    "    critic_steps=CRITIC_STEPS, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    n_epochs=N_EPOCHS,\n",
    "    lr=LR,\n",
    "    clip_c=CLIP_C,\n",
    "    use_cuda=USE_CUDA\n",
    ")\n",
    "\n",
    "plot_losses(train_losses['discriminator_losses'], 'Critic loss')\n",
    "plot_losses(train_losses['generator_losses'], 'Generator loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ay6-MjQGjO1V"
   },
   "outputs": [],
   "source": [
    "samples, grid, critic_output = make_inference(generator, critic)\n",
    "visualize_critic_output(samples, grid, critic_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZG4ErQLNjZr9"
   },
   "source": [
    "## WGAN-GP\n",
    "\n",
    "[WGAN-GP](https://arxiv.org/pdf/1704.00028.pdf)  model uses gradient penalty to enforce Lipschitzness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPCritic(MLPDiscriminator):\n",
    "    def clip_weights(self, c):\n",
    "        for layer in self.mlp.net:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                layer.weight = nn.Parameter(torch.clamp(layer.weight, -c, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OH4WAoWXi1s0"
   },
   "outputs": [],
   "source": [
    "def gradient_penalty(critic, real_data, fake_data):\n",
    "    batch_size = real_data.shape[0]\n",
    "\n",
    "    # ====\n",
    "    # your code\n",
    "    # calculate interpolation x_t = t * x_real + (1 - t) x_fake\n",
    "    # 1) sample t\n",
    "    # 2) create x_t (be careful about shapes)\n",
    "\n",
    "\n",
    "    # ====\n",
    "\n",
    "    # ====\n",
    "    # your code\n",
    "    # apply critic to x_t\n",
    "\n",
    "\n",
    "    # ====\n",
    "    \n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=d_output, \n",
    "        inputs=interpolated, \n",
    "        grad_outputs=torch.ones(d_output.size()).cuda(), \n",
    "        create_graph=True, \n",
    "        retain_graph=True\n",
    "    )[0]\n",
    "\n",
    "    gradients = gradients.reshape(batch_size, -1)\n",
    "    # ====\n",
    "    # your code\n",
    "    # compute gradient norm\n",
    "\n",
    "    # ====\n",
    "    return ((gradients_norm - 1) ** 2).mean()\n",
    "\n",
    "\n",
    "def train_wgan_gp(\n",
    "    generator, \n",
    "    critic, \n",
    "    train_loader,\n",
    "    critic_steps, \n",
    "    batch_size,\n",
    "    n_epochs,\n",
    "    lr, \n",
    "    gp_weight=10,\n",
    "    use_cuda=False\n",
    "):\n",
    "\n",
    "    if use_cuda:\n",
    "        critic = critic.cuda()\n",
    "        generator = generator.cuda()\n",
    "    critic.train()\n",
    "    generator.train()\n",
    "\n",
    "    gen_optimizer = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0, 0.9))\n",
    "    critic_optimizer = torch.optim.Adam(critic.parameters(), lr=lr, betas=(0, 0.9))\n",
    "\n",
    "    curr_iter = 0\n",
    "    d_loss, g_loss = torch.zeros(1), torch.zeros(1)\n",
    "    batch_loss_history = {'discriminator_losses': [], 'generator_losses': []}\n",
    "    for epoch_i in range(n_epochs):\n",
    "        with tqdm(train_loader, desc=f\"epoch {epoch_i}\", leave=False) as pbar:\n",
    "            for batch_i, x in enumerate(pbar):\n",
    "                curr_iter += 1\n",
    "                if use_cuda:\n",
    "                    x = x.cuda()\n",
    "\n",
    "                # do a critic update\n",
    "                critic_optimizer.zero_grad()\n",
    "                fake_data = generator.sample(x.shape[0])\n",
    "\n",
    "                # ====\n",
    "                # your code\n",
    "                # compute discriminator loss of D(x_fake) - D(x_real) + gp_weight * grad_pen\n",
    "\n",
    "                # ====\n",
    "\n",
    "                d_loss.backward()\n",
    "                critic_optimizer.step()\n",
    "                pbar.set_postfix({\"D loss\": d_loss.item(), \"G loss\": g_loss.item()})\n",
    "                # generator update\n",
    "                if curr_iter % critic_steps == 0:\n",
    "                    gen_optimizer.zero_grad()\n",
    "                    fake_data = generator.sample(batch_size)\n",
    "                    # ====\n",
    "                    # your code\n",
    "                    # compute generator loss as -D(x_fake)\n",
    "\n",
    "                    # ====\n",
    "                    g_loss.backward()\n",
    "                    gen_optimizer.step()\n",
    "                    pbar.set_postfix({\"D loss\": d_loss.item(), \"G loss\": g_loss.item()})\n",
    "\n",
    "                    batch_loss_history['generator_losses'].append(g_loss.data.cpu().numpy())\n",
    "                    batch_loss_history['discriminator_losses'].append(d_loss.data.cpu().numpy())\n",
    "\n",
    "    return batch_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M5RfNxTQjfU8"
   },
   "outputs": [],
   "source": [
    "# ====\n",
    "# your code\n",
    "# choose these parameters\n",
    "BATCH_SIZE = \n",
    "GEN_HIDDENS = \n",
    "DISCR_HIDDENS = \n",
    "CRITIC_STEPS = \n",
    "LR = \n",
    "GP_WEIGHT = \n",
    "# ====\n",
    "\n",
    "N_EPOCHS = 200\n",
    "train_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "generator = MLPGenerator(latent_dim=16, hiddens=GEN_HIDDENS, data_dim=2, use_sigmoid=False)\n",
    "critic = MLPCritic(data_dim=2, hiddens=DISCR_HIDDENS, use_sigmoid=False)\n",
    "\n",
    "losses = train_wgan_gp(\n",
    "    generator, \n",
    "    critic, \n",
    "    train_loader,\n",
    "    CRITIC_STEPS, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    n_epochs=N_EPOCHS,\n",
    "    lr=LR,\n",
    "    gp_weight=GP_WEIGHT,\n",
    "    use_cuda=USE_CUDA\n",
    ")\n",
    "\n",
    "plot_losses(train_losses['discriminator_losses'], 'Critic loss')\n",
    "plot_losses(train_losses['generator_losses'], 'Generator loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BLx-0sNajkID"
   },
   "outputs": [],
   "source": [
    "samples, grid, critic_output = make_inference(generator, critic)\n",
    "visualize_critic_output(samples, grid, critic_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8zInnwKIakS"
   },
   "source": [
    "# Task 4: WGAN-GP for CIFAR 10 (4pt)\n",
    "\n",
    "In this task you will fit [Wasserstein GAN](https://arxiv.org/abs/1701.07875) with [Gradient Penalty](https://arxiv.org/pdf/1704.00028.pdf) model to the CIFAR10 dataset (download it from [here](https://drive.google.com/file/d/16j3nrJV821VOkkuRz7aYam8TyIXLnNme/view?usp=sharing)).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B0l_BCGoaRs7"
   },
   "outputs": [],
   "source": [
    "def load_pickle(path, flatten=False, binarize=False):\n",
    "    with open(path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    train_data = data['train'].astype('float32')\n",
    "    test_data = data['test'].astype('float32')\n",
    "    if binarize:\n",
    "        train_data = (train_data > 128).astype('float32')\n",
    "        test_data = (test_data > 128).astype('float32')\n",
    "    else:\n",
    "        train_data = train_data / 255.\n",
    "        test_data = test_data / 255.\n",
    "    train_data = np.transpose(train_data, (0, 3, 1, 2))\n",
    "    test_data = np.transpose(test_data, (0, 3, 1, 2))\n",
    "    if flatten:\n",
    "        train_data = train_data.reshape(len(train_data.shape[0]), -1)\n",
    "        test_data = test_data.reshape(len(train_data.shape[0]), -1)\n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "def show_samples(samples, title, nrow=10):\n",
    "    samples = torch.FloatTensor(samples)\n",
    "    grid_img = make_grid(samples, nrow=nrow)\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.imshow(grid_img.permute(1, 2, 0))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_data(data, title):\n",
    "    idxs = np.random.choice(len(data), replace=False, size=(100,))\n",
    "    images = train_data[idxs]\n",
    "    show_samples(images, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dAvSLXlKZ5q7"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = load_pickle(os.path.join('drive', 'MyDrive', 'DGM', 'homework_supplementary', 'cifar10.pkl'))\n",
    "visualize_data(train_data, 'CIFAR10 samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nc9WGmMMkxTU"
   },
   "source": [
    "Here we will use convolution-based generator and discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7a7fjcx0vL8R"
   },
   "outputs": [],
   "source": [
    "class ConvGenerator(nn.Module):\n",
    "    def __init__(self, input_size=128, n_channels=64):\n",
    "        super().__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.input_size = input_size\n",
    "        # ====\n",
    "        # your code\n",
    "        # 1) define linear layer with output units 4 * 4 * 4 * n_channels, then relu\n",
    "        # 2) define transposed conv with stride 2, kernel size 2 then BN, then relu\n",
    "        # 3) define transposed conv with stride 2, kernel size 2 then BN, then relu\n",
    "\n",
    "        # ====\n",
    "\n",
    "    def forward(self, input):\n",
    "        # ====\n",
    "        # your code\n",
    "        # 1) apply all layers\n",
    "        # 2) the output should be in the range of [0, 1] (apply activation) \n",
    "\n",
    "\n",
    "        # ====\n",
    "        return output.view(-1, 3, 32, 32)\n",
    "\n",
    "    def sample(self, n_samples):\n",
    "        # ====\n",
    "        # your code\n",
    "        # sample from standard normal distribution and apply the model\n",
    "\n",
    "        # ====\n",
    "\n",
    "\n",
    "class ConvCritic(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super().__init__()\n",
    "        self.n_channels = n_channels\n",
    "        \n",
    "        # ====\n",
    "        # your code\n",
    "        # sequence of Conv2D with kernel size 3 stride 2 and LeakyRelU\n",
    "        \n",
    "        # ====\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ====\n",
    "        # your code\n",
    "        # apply all layers\n",
    "\n",
    "        # ====\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aY6qzJ5MSuiX"
   },
   "outputs": [],
   "source": [
    "# ====\n",
    "# your code\n",
    "# choose these parameters (you have to train the model more than 20 epochs to get good results)\n",
    "BATCH_SIZE = \n",
    "N_CHANNELS = \n",
    "N_EPOCHS = \n",
    "CRITIC_STEPS = \n",
    "GP_WEIGHT = \n",
    "LR = \n",
    "# ====\n",
    "\n",
    "train_data, test_data = load_pickle(os.path.join('drive', 'MyDrive', 'DGM', 'homework_supplementary', 'cifar10.pkl'))\n",
    "\n",
    "train_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "generator = ConvGenerator(n_channels=N_CHANNELS)\n",
    "critic = ConvCritic(n_channels=N_CHANNELS)\n",
    "\n",
    "train_losses = train_wgan_gp(\n",
    "    generator, \n",
    "    critic, \n",
    "    train_loader,\n",
    "    critic_steps=CRITIC_STEPS, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    n_epochs=N_EPOCHS,\n",
    "    lr=LR,\n",
    "    gp_weight=GP_WEIGHT,\n",
    "    use_cuda=USE_CUDA\n",
    ")\n",
    "\n",
    "plot_losses(train_losses['discriminator_losses'], 'Discriminator loss')\n",
    "plot_losses(train_losses['generator_losses'], 'Generator loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8I0pNzHchqRs"
   },
   "outputs": [],
   "source": [
    "generator.eval()\n",
    "critic.eval()\n",
    "with torch.no_grad():\n",
    "    samples = generator.sample(1000)\n",
    "    samples = samples.cpu().detach().numpy()\n",
    "    \n",
    "\n",
    "show_samples(samples[:100], title='CIFAR-10 generated samples')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "hw5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "12081ffdd81b4ed8b3dafcfeba20f038": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8e21e39a6e174ff89a8c1d610ac8b33a",
      "max": 50,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_39d2d0e8dd244b878f3ffac072857735",
      "value": 29
     }
    },
    "36c80d2acaa84e31ac6adfa58abe3c95": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39d2d0e8dd244b878f3ffac072857735": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4eb609f28a6a4d2682cd395078b66811": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a03b575469541f098b13ce9cb25616f",
      "placeholder": "​",
      "style": "IPY_MODEL_528331135467479c8b751660bdd63da8",
      "value": " 28/50 [01:04&lt;00:51,  2.34s/it]"
     }
    },
    "528331135467479c8b751660bdd63da8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5e87b91ffa4547a3babaaa36950f900f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6080bfc01258436ab0895d9a1f6e54c2",
       "IPY_MODEL_12081ffdd81b4ed8b3dafcfeba20f038",
       "IPY_MODEL_4eb609f28a6a4d2682cd395078b66811"
      ],
      "layout": "IPY_MODEL_36c80d2acaa84e31ac6adfa58abe3c95"
     }
    },
    "6080bfc01258436ab0895d9a1f6e54c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9936d1fdacf14b8c88a8b78f766c76e8",
      "placeholder": "​",
      "style": "IPY_MODEL_df95f674f8984c75ab91fdc406a26d35",
      "value": " 56%"
     }
    },
    "7a03b575469541f098b13ce9cb25616f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e21e39a6e174ff89a8c1d610ac8b33a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9936d1fdacf14b8c88a8b78f766c76e8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df95f674f8984c75ab91fdc406a26d35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
